# Natural Language Processing Cluster Template
# Use Case: Text analysis, topic modeling, sentiment analysis, NER, translation
# Domain: Computational Linguistics / Text Analytics
# Optimized for: Large-scale text processing, traditional NLP (not LLM training)
# Included software: SpaCy, NLTK, Gensim, Stanford NLP, transformers inference
# Instance recommendations: Compute (c5) for text processing, GPU for transformers
# Estimated costs: ~$1-2/hour for c5.4xlarge, ~$1-2/hour for g4dn.xlarge

cluster:
  name: nlp-cluster
  region: us-east-1

compute:
  # Head node for interactive analysis
  head_node: m5.xlarge

  queues:
    # Text processing queue for tokenization, parsing
    # SpaCy pipelines, POS tagging, NER
    - name: text-processing
      instance_types:
        - c5.2xlarge   # 8 vCPU, 16GB RAM
        - c5.4xlarge   # 16 vCPU, 32GB RAM
        - c5.9xlarge   # 36 vCPU, 72GB RAM
      min_count: 0
      max_count: 50

    # Topic modeling queue for LDA, NMF
    # Large vocabulary, document-term matrices
    - name: topic-modeling
      instance_types:
        - r5.2xlarge   # 8 vCPU, 64GB RAM
        - r5.4xlarge   # 16 vCPU, 128GB RAM
      min_count: 0
      max_count: 20

    # Transformer inference queue
    # BERT, RoBERTa for classification, NER
    - name: transformers
      instance_types:
        - g4dn.xlarge   # 1x T4 16GB
        - g4dn.2xlarge  # 1x T4 16GB
        - c5.4xlarge    # CPU inference
      min_count: 0
      max_count: 30

    # Document similarity and search
    # Vector embeddings, semantic search
    - name: similarity
      instance_types:
        - m5.2xlarge   # 8 vCPU, 32GB RAM
        - m5.4xlarge   # 16 vCPU, 64GB RAM
      min_count: 0
      max_count: 25

software:
  spack_packages:
    # Compilers
    - gcc@11.3.0

    # Python ecosystem
    - python@3.10.8
    - py-pip@23.0
    - py-numpy@1.24.0
    - py-scipy@1.10.0
    - py-pandas@2.0.0
    - py-matplotlib@3.7.0
    - py-scikit-learn@1.2.0

    # NLP libraries (install via pip)
    # - spacy (pip - industrial-strength NLP)
    # - nltk (pip - Natural Language Toolkit)
    # - gensim (pip - topic modeling)
    # - textblob (pip - simple NLP)
    # - polyglot (pip - multilingual NLP)

    # Transformers and deep learning
    - py-torch@2.0.0+cuda
    # - transformers (pip - Hugging Face)
    # - sentence-transformers (pip - embeddings)
    # - datasets (pip - NLP datasets)
    # - tokenizers (pip - fast tokenization)

    # Text processing
    # - ftfy (pip - fix text encoding)
    # - unidecode (pip - ASCII conversion)
    # - langdetect (pip - language detection)
    # - wordcloud (pip - visualization)

    # Topic modeling
    # - gensim (already listed)
    # - lda (pip - Latent Dirichlet Allocation)
    # - bertopic (pip - BERT-based topics)

    # Named Entity Recognition
    # - spacy-transformers (pip)
    # - flair (pip - NER and text classification)

    # Sentiment analysis
    # - vaderSentiment (pip)
    # - textblob (pip)

    # Information extraction
    # - newspaper3k (pip - article extraction)
    # - beautifulsoup4 (pip - HTML parsing)
    # - scrapy (pip - web scraping)

    # Visualization
    - py-plotly@5.14.0
    - py-seaborn@0.12.0

    # Jupyter
    - py-jupyter@1.0.0
    - py-jupyterlab@3.6.0

    # Database for text storage
    - postgresql@15.2
    # - elasticsearch (manual - full-text search)

    # GPU support
    - cuda@11.8.0
    - cudnn@8.6.0
    - nvtop@2.0.0

    # Utilities
    - git@2.40.0
    - parallel@20230422
    - tmux@3.3a
    - htop@3.2.1

users:
  - name: nlpuser1
    uid: 3001
    gid: 3001
  - name: nlpuser2
    uid: 3002
    gid: 3002

data:
  s3_mounts:
    # Raw text corpora
    - bucket: my-nlp-corpora
      mount_point: /shared/corpora

    # Processed and tokenized data
    - bucket: my-nlp-processed
      mount_point: /shared/processed

    # Models and embeddings
    - bucket: my-nlp-models
      mount_point: /shared/models

    # Analysis results
    - bucket: my-nlp-results
      mount_point: /shared/results
